{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5849c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e52df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Replace 'your_api_key_here' with your actual API key\n",
    "openai.api_key = 'your_api_key_here'\n",
    "\n",
    "headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai.api_key}\",\n",
    "    }\n",
    "\n",
    "# This is the main GPT prompt.  This instruction will be combined with the text of the chat transcript.  This prompt should include the entire definition of the code scale, as well as examples of difficult issues and how to address them. It must also address the format of the desired response.\n",
    "# Example prompt:\n",
    "prompt1 = \"\"\"\n",
    "Your response must be in this format and order:\n",
    "DESIRED FORMAT\n",
    "\n",
    "You are classifying a library chat transcript based on the following scale to score library chat interactions: EXAMPLE READ SCALE\n",
    "Score 0 - Not a question; Prank; Error\n",
    "Score 1 - No specialized knowledge, no resource consultation (includes canned resource links).  Examples:  Directional questions for locations within the library; Any question answered without resource consultation; Library Hours; Public access point phone numbers\n",
    "Score 2 - Minimal skills, nominal resource consultation.  Examples:  Call number directions; Library policy; Known item search; Individual staff contact information\n",
    "Score 3 - Some reference knowledge required and/or some effort required.  Examples: Topic search in single database; Basic instruction on searching; finding subject databases; complex technical tasks (e.g. how to save PDFs or export citations)\n",
    "Score 4 - Advanced reference, multiple sources, subject knowledge useful but not required.  Examples:  Lengthy topic searches for multiple document types;  Multiple topic searches across databases\n",
    "Score 5 - Subject knowledge required, lengthy consultation, multiple resources.\n",
    "Score 6 - Research effort beyond patron interaction.  Should never happen in chat reference.\n",
    "Score Unclear - not enough information in the transcript to make a clear decision\n",
    "\n",
    "Further instructions and clarifications:\n",
    "ADDITIONAL INSTRUCTIONS\n",
    "\n",
    "Transcript (starting with initial question):\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#In the Springshare LibChat export, the initial question and the chat transcript are separated into 2 columns.\n",
    "#We need to create a text file with the initial question + chat transcript combined.  Each transcript should be on a single line.\n",
    "#Additional data cleaning may be helpful, but does not seem to be strictly necessary.\n",
    "#Input file should be in UTF-16 encoding\n",
    "\n",
    "input_file = \"input_file.txt\"\n",
    "\n",
    "# Read the file as binary and decode it, ignoring NUL characters\n",
    "with open(input_file, \"rb\") as file:\n",
    "    content = file.read().decode(\"utf-16\", errors=\"ignore\")\n",
    "\n",
    "# Convert the decoded content into a list of lines\n",
    "lines = content.splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ffa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_text_and_save_response(prompt, line_number):\n",
    "    \n",
    "    \n",
    "    # Call the GPT-4 API\n",
    "    response = openai.Completion.create(**params)\n",
    "    \n",
    "    # Extract the response text\n",
    "    response_text = response.choices[0].text.strip()\n",
    "    \n",
    "    # Save the response to a new file\n",
    "    output_file_name = f\"gpt3_response_{line_number}.txt\"\n",
    "    with open(output_file_name, \"w\") as output_file:\n",
    "        output_file.write(response_text)\n",
    "    \n",
    "    print(f\"Response saved to '{output_file_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e315ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_text_and_save_response(prompt, line_number):\n",
    "    # Set your OpenAI API key\n",
    "    api_key = \"your_api_key_here\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "    }\n",
    "\n",
    "    # Set the parameters for the GPT-4 API call\n",
    "    # gpt-4 model is costlier, but has been shown to increase accuracy from 75% to 96%\n",
    "    # Other parameters will affect the output but have not been systematically tested\n",
    "    data = {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                     {\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 400,\n",
    "        \"n\": 1,\n",
    "        \"stop\": None,\n",
    "    }\n",
    "    \n",
    "    # Call the GPT-4 API with the chat-completions endpoint\n",
    "    # A timer is set to reduce the number of errors due to timeout\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, data=json.dumps(data))\n",
    "    \n",
    "    if response.status_code == 429:\n",
    "        time.sleep(2)\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, data=json.dumps(data))\n",
    "        \n",
    "        if response.status_code == 429:\n",
    "            time.sleep(30)\n",
    "            response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, data=json.dumps(data))\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                response_data = response.json()\n",
    "                print(\"Response data:\", response_data)\n",
    "                # Extract the response text\n",
    "                response_text = response_data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "                # Save the response to a new file\n",
    "                output_file_name = f\"gpt3_response.txt\"\n",
    "                with open(output_file_name, \"a\", encoding=\"utf-8\") as output_file:\n",
    "                    output_file.write(str(line_number) + \";\" + response_text + \"\\n\")\n",
    "                    print(f\"Response saved to '{output_file_name}'\")\n",
    "    \n",
    "        \n",
    "            else:\n",
    "                print(f\"Error: Request failed with status code {response.status_code}\")\n",
    "                print(f\"Response content: {response.content}\")\n",
    "            \n",
    "            \n",
    "            \n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            print(\"Response data:\", response_data)\n",
    "            # Extract the response text\n",
    "            response_text = response_data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "            # Save the response to a new file\n",
    "            output_file_name = f\"gpt3_response.txt\"\n",
    "            with open(output_file_name, \"a\", encoding=\"utf-8\") as output_file:\n",
    "                output_file.write(str(line_number) + \";\" + response_text + \"\\n\")\n",
    "                print(f\"Response saved to '{output_file_name}'\")\n",
    "    \n",
    "        \n",
    "        else:\n",
    "            print(f\"Error: Request failed with status code {response.status_code}\")\n",
    "            print(f\"Response content: {response.content}\")\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            print(\"Response data:\", response_data)\n",
    "            # Extract the response text\n",
    "            response_text = response_data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "            # Save the response to a new file\n",
    "            output_file_name = f\"gpt3_response.txt\"\n",
    "            with open(output_file_name, \"a\", encoding=\"utf-8\") as output_file:\n",
    "                output_file.write(str(line_number) + \";\" + response_text + \"\\n\")\n",
    "                print(f\"Response saved to '{output_file_name}'\")\n",
    "    \n",
    "        \n",
    "        else:\n",
    "            print(f\"Error: Request failed with status code {response.status_code}\")\n",
    "            print(f\"Response content: {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8282c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "# Read the input file\n",
    "with open(input_file, \"r\", encoding=\"utf-16\") as file:\n",
    "    file_reader = csv.reader(file, delimiter='\\t')\n",
    "    index = 0\n",
    "    for line in file_reader:\n",
    "        print(f\"Processing line {index}\")\n",
    "        print(line)\n",
    "\n",
    "        # Send the text and save the response\n",
    "        send_text_and_save_response(prompt1 + \" \" + line[0], index)\n",
    "\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd1945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
